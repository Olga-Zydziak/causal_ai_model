{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ CAUSAL AI - Quick Start\n",
    "\n",
    "Ten notebook przeprowadzi Ciƒô przez ca≈Çy pipeline w 4 krokach.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAP 1: Causal Discovery\n",
    "Odkrywamy strukturƒô przyczynowƒÖ z danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from causal_discovery_engine import discover_causal_graph\n",
    "\n",
    "# Za≈Çaduj dane\n",
    "df = pd.read_csv(\"fraud_data.csv\")\n",
    "print(f\"‚úì Dane za≈Çadowane: {len(df)} wierszy, {len(df.columns)} kolumn\")\n",
    "print(f\"  Kolumny: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcjonalnie: za≈Çaduj ground truth do walidacji\n",
    "with open(\"synthetic_data/ground_truth_metadata.json\") as f:\n",
    "    gt = json.load(f)\n",
    "\n",
    "gt_matrix = np.array(gt[\"ground_truth\"][\"adjacency_matrix\"])\n",
    "gt_variables = gt[\"ground_truth\"][\"variable_order\"]\n",
    "\n",
    "print(f\"‚úì Ground truth za≈Çadowany: {len(gt_variables)} zmiennych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uruchom discovery (wybierz algorytm: 'lingam', 'pc', lub 'ges')\n",
    "result = discover_causal_graph(\n",
    "    data=df,\n",
    "    algorithm=\"lingam\",\n",
    "    ground_truth=gt_matrix,\n",
    "    ground_truth_variables=gt_variables,\n",
    "    print_report=True,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Etap 1: Discovery complete\")\n",
    "print(f\"  Odkryte krawƒôdzie: {len(result.edges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz wynik do JSON\n",
    "discovery_output = {\n",
    "    \"algorithm\": result.algorithm,\n",
    "    \"discovered_graph\": {\n",
    "        \"edges\": [\n",
    "            {\n",
    "                \"source\": e.source,\n",
    "                \"target\": e.target,\n",
    "                \"strength\": float(e.strength) if e.strength else 1.0,\n",
    "            }\n",
    "            for e in result.edges\n",
    "        ],\n",
    "        \"variables\": result.variable_names,\n",
    "    },\n",
    "    \"metrics\": {\n",
    "        \"precision\": result.metrics.precision if result.metrics else None,\n",
    "        \"recall\": result.metrics.recall if result.metrics else None,\n",
    "        \"f1\": result.metrics.f1_score if result.metrics else None,\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"discovery_result.json\", \"w\") as f:\n",
    "    json.dump(discovery_output, f, indent=2)\n",
    "\n",
    "print(\"‚úì Zapisano: discovery_result.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAP 2: Human-in-the-Loop Review\n",
    "Zatwierdzamy odkryte relacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal_graph_review_svg import review_causal_graph\n",
    "\n",
    "reviewer = review_causal_graph(\n",
    "    discovery_path=\"discovery_result.json\",\n",
    "    ground_truth_path=\"synthetic_data/ground_truth_metadata.json\",\n",
    ")\n",
    "\n",
    "# Interfejs pojawi siƒô poni≈ºej\n",
    "# Kliknij \"Auto-approve\" lub zatwierd≈∫ rƒôcznie ka≈ºdƒÖ krawƒôd≈∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WA≈ªNE: Uruchom tƒô kom√≥rkƒô PO zatwierdzeniu w UI powy≈ºej\n",
    "reviewer.save_approved(\"approved_graph.json\")\n",
    "print(\"‚úì Etap 2: Review complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Alternatywa) Auto-approve bez UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je≈õli nie chcesz u≈ºywaƒá UI - odkomentuj i uruchom:\n",
    "\n",
    "# from causal_graph_review_svg import review_causal_graph, EdgeStatus\n",
    "# reviewer = review_causal_graph(\"discovery_result.json\", \"synthetic_data/ground_truth_metadata.json\")\n",
    "# for edge in reviewer.edges.values():\n",
    "#     edge.status = EdgeStatus.APPROVED\n",
    "#     edge.approved_strength = edge.ground_truth or edge.discovered_strength\n",
    "# reviewer.save_approved(\"approved_graph.json\")\n",
    "# print(\"‚úì Auto-approved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAP 3: Causal Effect Estimation (ATE/CATE)\n",
    "Obliczamy si≈Çƒô efekt√≥w przyczynowych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causal_effect_estimator import CausalEffectEstimator\n",
    "\n",
    "estimator = CausalEffectEstimator.from_files(\n",
    "    approved_graph_path=\"approved_graph.json\",\n",
    "    data_path=\"fraud_data.csv\",\n",
    "    outcome_variable=\"is_fraud\",\n",
    ")\n",
    "\n",
    "report = estimator.estimate_all()\n",
    "report.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapisz wyniki\n",
    "report.to_json(\"causal_effects_report.json\")\n",
    "report.to_html(\"causal_effects_report.html\")\n",
    "print(\"‚úì Etap 3: Effects complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETAP 4: Counterfactual Reasoning\n",
    "\"Co by by≈Ço gdyby?\" dla pojedynczych transakcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from counterfactual_engine import analyze_transaction\n",
    "\n",
    "# Zdefiniuj transakcjƒô do analizy\n",
    "transaction = {\n",
    "    \"transaction_amount\": 15000,\n",
    "    \"merchant_risk_score\": 0.75,\n",
    "    \"transaction_velocity_24h\": 6,\n",
    "    \"account_age_days\": 60,\n",
    "    \"is_foreign_transaction\": 1,\n",
    "    \"device_fingerprint_age_days\": 10,\n",
    "}\n",
    "\n",
    "# Analiza\n",
    "result = analyze_transaction(transaction)\n",
    "print(\"‚úì Etap 4: Counterfactual complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéâ GOTOWE!\n",
    "\n",
    "Masz teraz:\n",
    "- `discovery_result.json` - odkryty graf\n",
    "- `approved_graph.json` - zatwierdzony graf\n",
    "- `causal_effects_report.json` - wyniki ATE/CATE\n",
    "- Analizƒô counterfactual dla wybranej transakcji\n",
    "\n",
    "---\n",
    "\n",
    "## ‚û°Ô∏è Nastƒôpne kroki\n",
    "\n",
    "1. **Walidacja:** Uruchom `validation.ipynb` ≈ºeby por√≥wnaƒá discovery z ground truth\n",
    "2. **Eksperymentuj:** Zmie≈Ñ algorytm na 'pc' lub 'ges' i por√≥wnaj wyniki\n",
    "3. **Analizuj:** Sprawd≈∫ r√≥≈ºne transakcje w counterfactual engine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
